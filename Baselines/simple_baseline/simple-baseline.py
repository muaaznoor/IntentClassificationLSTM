# -*- coding: utf-8 -*-
"""simple-baseline

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JsL40-Uc61mWiNLdbmH914342FHqCejL

# Simple Baseline Implementation

## Markdown Commentary

### Description of Simple Baseline 

In this `simple-baseline.py` script, we attempt to construct two such simple baselines: the majority class baseline and a KNN classifier baseline. 

The majority class baseline simply predicts the label that shows up most frequently in the training set for all examples. In the training set, the majority class is `label = 50` corresponding to `label_text = calendar_set`, which makes up a mere 7.035% of the dataset. Using this majority prediction, we have a training accuracy of 7.035% and testing accuracy of **7.028%**, which are incredibly low but consistent hence underfit. This would be far too trivial to beat.

As a result, we tried to explore a better but still naive baseline by running a Nearest Neighbors Classifier with $k = 1$ that uses Glove embeddings to compute the embedding of each word in an example text, then averages them to get a sentence level embedding for the example. We do this for all examples in both train and test sets. Then, for each testing example, we compute the cosine similarity of its sentence level embedding with the embedding of each of the training examples. The label of this testing example is then taken to be the same label as the training example with the highest cosine similarity. This baseline produced a testing accuracy of **74.65%**, which is somewhat more realistic as a simple baseline to beat.

### Sample Output

#### Majority Baseline Predictions
`majority_test_preds = [50, 50, 50, 50, 50 ... , 50, 50, 50, 50, 50]`

#### KNN Baseline Predictions 
`test_preds = [48, 46, 1, 18, 40, ..., 33, 44, 44, 44, 44]`

#### Actual (Gold) Test Labels
`df_test['labels'] = [48, 46, 1, 41, 40, ..., 33, 44, 44, 44, 44]`


### How to Use This

This script runs in a linear fashion to return the scores for both simple baseline - no user inputs needed.

## Imports
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import random 
np.random.seed(42)

# NLTK, NumPy, and Pandas.
import nltk
nltk.download('punkt')
from nltk.tree import Tree
from numpy import random as rd
from nltk.tokenize import word_tokenize
import random

import collections
import re
import time
import itertools
from collections import defaultdict, Counter
from IPython.display import clear_output 

import glob
from argparse import ArgumentParser

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

"""## Load Dataset"""

from google.colab import drive
drive.mount('/content/drive')

df_train = pd.read_json("/content/drive/Shareddrives/CIS-5300_Final-Project/train.jsonl", lines=True)
df_train.shape

df_validation = pd.read_json("/content/drive/Shareddrives/CIS-5300_Final-Project/validation.jsonl", lines=True)
df_validation.shape

df_test = pd.read_json("/content/drive/Shareddrives/CIS-5300_Final-Project/test.jsonl", lines=True)
df_test.shape

"""## Option 1: Majority Class"""

# Simple Baseline's Train Accuracy
simple_train_acc = df_train['label_text'].value_counts(normalize = True).head(1).values[0]
print(f"The Simple Majority Class Baseline has a training accuracy of {round(simple_train_acc*100,3)}%")

# Get label
majority_label = df_train['label'].value_counts(normalize = True).index[0]
majority_label_name = df_train['label_text'].value_counts(normalize = True).index[0]
majority_test_preds = [majority_label] * df_test.shape[0]

print(f"The majority class label is {majority_label} which refers to the text label {majority_label_name}")

# Test Accuracy
simple_test_acc = sum([majority_label == test_label for test_label in df_test['label']])/df_test.shape[0]
print(f"The Simple Majority Class Baseline has a testing accuracy of {round(simple_test_acc*100,3)}%")

"""## Option 2: KNN via Word2Vec and Cosine Similarity

### [Glove Embeddings](https://nlp.stanford.edu/projects/glove/) 
We are downloading pretrained glove word vectors that has been trained on Common Crawl data, a snapshot of the whole web.
These embeddings serve as excelent initilizations for embeddings our model needs.
Downloading glove embeddings (This will take around 10 minutes)
"""

#this takes about 10 minutes to run
#!wget -nc https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip
!unzip /content/drive/Shareddrives/CIS-5300_Final-Project/glove.840B.300d.zip
!ls -lat

glove_file = "glove.840B.300d.txt"

"""#### Create Vocab Set"""

df_all = pd.concat([df_train, df_validation, df_test]).reset_index()

tokenized_data = [word_tokenize(df_all['text'][i]) for i in range(len(df_all['text']))]

vocab = {word for sentence in tokenized_data for word in sentence}

"""#### Get Glove embeddings"""

# Takes about 1 minute to read through the whole file and find the words we need. Adapted from HW3
def get_glove_mapping(vocab, file):
    """
    Gets the mapping of words from the vocabulary to pretrained embeddings
    
    INPUT:
    vocab       - set of vocabulary words
    file        - file with pretrained embeddings

    OUTPUT:
    glove_map   - mapping of words in the vocabulary to the pretrained embedding
    
    """
    
    glove_map = {}
    with open(file,'rb') as fi:
        for l in fi:
            try:
                emd_lst = l.decode().split(' ')
                word = emd_lst.pop(0)
                emd_lst = [float(n) for n in emd_lst]

                if word in vocab:
                  glove_map[word] = np.array(emd_lst)
            except:
                pass
    return glove_map

# Get the glove maps
glove_map = get_glove_mapping(vocab,glove_file)

# from gensim.models import Word2Vec
# from gensim.test.utils import common_texts
from sklearn.metrics.pairwise import cosine_similarity

# Define helper for cosine similarity
def cosine_similarity(u,v):
  return np.dot(u,v)/(np.linalg.norm(v)*np.linalg.norm(u))

# Run training loop
train_sentence_embeddings = []

# for text in df_train:
for i in range(len(df_train)):
  text = df_train['text'][i]
  word_list = text.split()

  # Get word embeddings
  word_embeddings = [glove_map[word] if word in glove_map.keys() else np.random.normal(size = 300) for word in word_list]
  
  # Compute sentence embedding as the average of the word embeddings
  average_emb = np.mean(word_embeddings, axis = 0)
  train_sentence_embeddings.append(average_emb)

# Get testing embeddings and predictions
test_sentence_embeddings = []
test_preds = []

# for text in df_test:
for i in range(len(df_test)):
  clear_output()
  print("Test Iteration: ", i, "\n")
  text = df_test['text'][i]
  word_list = text.split()

  # Get word embeddings
  word_embeddings = [glove_map[word] if word in glove_map.keys() else np.random.normal(size = 300) for word in word_list]
  
  # Compute sentence embedding as the average of the word embeddings
  average_emb = np.mean(word_embeddings, axis = 0)
  # test_sentence_embeddings.append(average_emb)

  # For this embedding, compare vs. all train embeddings and then argmax and back out the label from the training
  cosine_sim_list = [cosine_similarity(average_emb, train_example_emb) for train_example_emb in train_sentence_embeddings]

  max_train_idx = np.argmax(cosine_sim_list)
  test_preds.append(df_train['label'][max_train_idx])

# Visualize
pd.DataFrame({'KNN Test Predictions': test_preds,
              'Gold Test Label': list(df_test['label'])})

# Get Simple KNN Baseline Testing Accuracy
print(f"Simple KNN Baseline Testing Accuracy: {round(100*sum(test_preds == df_test.label)/len(df_test.label),3)}%")